{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/rXi/HpDA2NS/rqjDdVlk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zamoraricardo15/Intro-to-Health-Informatics/blob/main/Covid_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Approximation for misinformation estimation: COVID-19"
      ],
      "metadata": {
        "id": "9KF8c68roZih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4S0PFHI7zQNR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4a27380-5606-48c6-e529-d3cc3b6a704c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_text"
      ],
      "metadata": {
        "id": "I2VhgwtwYmAz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3652226-69e7-4b2b-9703-075f338ffaae"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_text\n",
            "  Downloading tensorflow_text-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 29.0 MB/s \n",
            "\u001b[?25hCollecting tensorflow<2.12,>=2.11.0\n",
            "  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 588.3 MB 15 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (57.4.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (0.28.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.21.6)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (3.19.6)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.14.1)\n",
            "Collecting tensorboard<2.12,>=2.11\n",
            "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 41.9 MB/s \n",
            "\u001b[?25hCollecting keras<2.12,>=2.11.0\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 44.8 MB/s \n",
            "\u001b[?25hCollecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.11.23-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (4.1.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (2.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (3.3.0)\n",
            "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[K     |████████████████████████████████| 439 kB 61.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.3.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (14.0.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (21.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.50.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.38.4)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.14.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.4.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2022.9.24)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.0.9)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, flatbuffers, tensorflow, tensorflow-text\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "Successfully installed flatbuffers-22.11.23 keras-2.11.0 tensorboard-2.11.0 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-text-2.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iPNwmPtXPXOo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as tfl\n",
        "import zipfile\n",
        "from tensorflow.keras import Sequential, Input\n",
        "from tensorflow.keras.utils import get_file\n",
        "from sklearn.model_selection import train_test_split\n",
        "BATCH_SIZE = 64"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fake_df = pd.DataFrame(dict(title=[], isFakeNews=[], src=[]))"
      ],
      "metadata": {
        "id": "ySgQZnBNRxP5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fake and real news dataset:\n",
        "https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset"
      ],
      "metadata": {
        "id": "1wov_d3zo6Z1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fakecsv_df = pd.read_csv('/content/Fake.csv')\n",
        "truecsv_df = pd.read_csv('/content/True.csv')\n",
        "\n",
        "fakecsv_df['isFakeNews'] = True\n",
        "truecsv_df['isFakeNews'] = False\n",
        "fakecsv_df['src'] = 'Fake-and-real-news-dataset'\n",
        "truecsv_df['src'] = 'Fake-and-real-news-dataset'\n",
        "fake_df = fake_df\\\n",
        "                    .append(fakecsv_df[['title', 'isFakeNews', 'src']])\\\n",
        "                    .append(truecsv_df[['title', 'isFakeNews', 'src']])"
      ],
      "metadata": {
        "id": "UOYIfb03TB38"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FakeNewsNet:\n",
        "https://github.com/KaiDMML/FakeNewsNet"
      ],
      "metadata": {
        "id": "WaUnzXIYpWvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "politic_df = pd.read_csv(\"/content/politifact_real.csv\")\n",
        "politifake_df = pd.read_csv(\"/content/politifact_fake.csv\")\n",
        "politic_df['isFakeNews'] = False\n",
        "politifake_df['isFakeNews'] = True\n",
        "politifact_df = politic_df.append(politifake_df)\n",
        "politifact_df['src'] = 'FakeNewsNet/politifact'\n",
        "fake_df = fake_df.append(politifact_df[['title', 'isFakeNews', 'src']])"
      ],
      "metadata": {
        "id": "J3accQ3XSESU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "realgossip_df = pd.read_csv(\"/content/gossipcop_real.csv\")\n",
        "fakegossip_df = pd.read_csv(\"/content/gossipcop_fake.csv\")\n",
        "realgossip_df['isFakeNews'] = False\n",
        "fakegossip_df['isFakeNews'] = True\n",
        "gossipcop_df = realgossip_df.append(fakegossip_df)\n",
        "gossipcop_df['src'] = 'FakeNewsNet/gossipcop'\n",
        "fake_df = fake_df.append(gossipcop_df[['title', 'isFakeNews', 'src']])"
      ],
      "metadata": {
        "id": "AFz-HitDSRhi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "COVID-19 Rumor Dataset:\n",
        "https://github.com/MickeysClubhouse/COVID-19-rumor-dataset"
      ],
      "metadata": {
        "id": "F_B5ZtrEqFZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "newss_df = pd.read_csv('/content/en_dup.csv')\n",
        "newss_df = newss_df[~(newss_df['label'] == 'U')] \n",
        "newss_df['label'] = newss_df['label']  == 'F' \n",
        "newss_df['src'] = 'COVID-19-rumor-dataset' \n",
        "newss_df = newss_df[['label', 'content', 'src']].rename(columns={'label':'isFakeNews','content':'title'}) \n",
        "fake_df = fake_df.append(newss_df)"
      ],
      "metadata": {
        "id": "dEugWKFVR2AG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FakeCovid:\n",
        "https://github.com/Gautamshahi/FakeCovid"
      ],
      "metadata": {
        "id": "QKCDlARFqKRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jun_df = pd.read_csv(\"/content/FakeCovid_June2020.csv\")\n",
        "jul_df = pd.read_csv(\"/content/FakeCovid_July2020.csv\")\n",
        "jun_df.loc[jun_df['class'] == 'TRUE', 'isFakeNews'] = False\n",
        "jul_df.loc[jul_df['class'] == 'TRUE', 'isFakeNews'] = False\n",
        "jun_df['isFakeNews'].fillna(True, inplace = True)\n",
        "jul_df['isFakeNews'].fillna(True, inplace = True)\n",
        "jun_df['src'] = 'FakeCovid'\n",
        "jul_df['src'] = 'FakeCovid'\n",
        "fake_df = fake_df\\\n",
        "                    .append(jun_df[['ref_title', 'isFakeNews','src']].rename(columns={'ref_title':'title'}))\\\n",
        "                    .append(jul_df[['source_title', 'isFakeNews','src']].rename(columns={'source_title':'title'}))"
      ],
      "metadata": {
        "id": "q5HREYqIUHv7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake_df.dropna(inplace=True)\n",
        "fake_df.to_csv(\"data_fake_df.csv\", index=False)"
      ],
      "metadata": {
        "id": "s0pI4ZzAVJQb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake_df.head()"
      ],
      "metadata": {
        "id": "6hIDDKLbVfHs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "7f8b16f4-64a7-4f00-b613-491c5ceaa533"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  isFakeNews  \\\n",
              "0   Donald Trump Sends Out Embarrassing New Year’...         1.0   \n",
              "1   Drunk Bragging Trump Staffer Started Russian ...         1.0   \n",
              "2   Sheriff David Clarke Becomes An Internet Joke...         1.0   \n",
              "3   Trump Is So Obsessed He Even Has Obama’s Name...         1.0   \n",
              "4   Pope Francis Just Called Out Donald Trump Dur...         1.0   \n",
              "\n",
              "                          src  \n",
              "0  Fake-and-real-news-dataset  \n",
              "1  Fake-and-real-news-dataset  \n",
              "2  Fake-and-real-news-dataset  \n",
              "3  Fake-and-real-news-dataset  \n",
              "4  Fake-and-real-news-dataset  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-890aea15-a078-413e-a52f-d0c172fadfda\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>isFakeNews</th>\n",
              "      <th>src</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Fake-and-real-news-dataset</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Fake-and-real-news-dataset</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Fake-and-real-news-dataset</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Fake-and-real-news-dataset</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Fake-and-real-news-dataset</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-890aea15-a078-413e-a52f-d0c172fadfda')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-890aea15-a078-413e-a52f-d0c172fadfda button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-890aea15-a078-413e-a52f-d0c172fadfda');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_data = \"/content/data_fake_df.csv\"\n",
        "df = pd.read_csv(df_data)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "K0MT9WGew7V_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "018009ad-5175-4320-f868-593173202e9a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  isFakeNews  \\\n",
              "0   Donald Trump Sends Out Embarrassing New Year’...         1.0   \n",
              "1   Drunk Bragging Trump Staffer Started Russian ...         1.0   \n",
              "2   Sheriff David Clarke Becomes An Internet Joke...         1.0   \n",
              "3   Trump Is So Obsessed He Even Has Obama’s Name...         1.0   \n",
              "4   Pope Francis Just Called Out Donald Trump Dur...         1.0   \n",
              "\n",
              "                          src  \n",
              "0  Fake-and-real-news-dataset  \n",
              "1  Fake-and-real-news-dataset  \n",
              "2  Fake-and-real-news-dataset  \n",
              "3  Fake-and-real-news-dataset  \n",
              "4  Fake-and-real-news-dataset  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c282c963-35f3-40c0-9970-8d26747b3996\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>isFakeNews</th>\n",
              "      <th>src</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Fake-and-real-news-dataset</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Fake-and-real-news-dataset</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Fake-and-real-news-dataset</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Fake-and-real-news-dataset</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Fake-and-real-news-dataset</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c282c963-35f3-40c0-9970-8d26747b3996')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c282c963-35f3-40c0-9970-8d26747b3996 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c282c963-35f3-40c0-9970-8d26747b3996');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lenmmax = df[\"title\"].apply(lambda x : len(x.split())).max()\n",
        "worcount = 100000\n",
        "length_data = len(df)\n",
        "length_data"
      ],
      "metadata": {
        "id": "KH75tGgAxK3h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "898b052d-8099-4a80-dd24-85fcd9b73831"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86002"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(dataset, length_data, val_split=0.2, shuffle=True, shuffle_size=50000):\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(shuffle_size, seed=42)\n",
        "    train_size = int((1-val_split) * length_data)\n",
        "    val_size = int(val_split * length_data)\n",
        "    try:\n",
        "      train_ds = dataset.take(train_size).map(lambda x : (x[\"title\"], x[\"isFakeNews\"]))\n",
        "      val_ds = dataset.skip(train_size).take(val_size).map(lambda x : (x[\"title\"], x[\"isFakeNews\"]))\n",
        "    except:\n",
        "      train_ds = dataset.take(train_size)\n",
        "      val_ds = dataset.skip(train_size).take(val_size)\n",
        "    train_ds = train_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    val_ds = val_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    return train_ds, val_ds"
      ],
      "metadata": {
        "id": "Oevo73bBZUZO"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = tf.data.experimental.make_csv_dataset(df_data, select_columns=[\n",
        "    \"title\",\n",
        "    \"isFakeNews\"                                                                    \n",
        "], batch_size=BATCH_SIZE)\n",
        "\n",
        "train_ds, val_ds = train_test_split(ds, length_data)\n",
        "val_ds, test_ds = train_test_split(val_ds, int(length_data * 0.2), val_split=0.5)"
      ],
      "metadata": {
        "id": "j-rMZfsWZW70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6759e4f-9248-461e-cf4f-6a2dc61f5d4a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_letters(text):\n",
        "  marksp = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
        "  sowords = {'whom', 'all', 'shouldn', 'wouldn', 'how', 's', 'they', 'were', 'mustn', 'after', 'who', 'its', 'our', 't', 'a', 'very', 'an', 'do', 'be', 'to', 'can', 'had', 'i', 'these', 'himself', 'up', 'just', 'them', 'now', 'has', 'too', 'below', 'did', 'shan', 'until', 'during', 'him', 'into', 'have', \"you'd\", 'haven', 'theirs', 'ourselves', 'once', \"isn't\", 'than', \"it's\", 'wasn', 'yours', \"mightn't\", 'here', 'ours', 'her', 'doing', 'd', 'yourself', 'y', 'before', 'does', 'then', 'between', 'some', 'with', \"needn't\", 'but', 'didn', \"shouldn't\", 'that', \"weren't\", 'which', 'or', \"hasn't\", 'own', 'about', 'what', \"aren't\", 'couldn', 'doesn', 'as', \"wouldn't\", 'hasn', 'no', 'm', 'hers', 'hadn', 'aren', 'while', 'will', \"don't\", \"shan't\", 'why', 'at', 'mightn', 'themselves', 'weren', \"that'll\", 'isn', 'only', 'the', 'been', \"couldn't\", 'don', 'should', 'same', 'both', 'where', 'was', 'me', 'through', \"hadn't\", 've', 'against', 'if', 'under', 'such', 'is', 'll', \"haven't\", 'ain', 're', \"didn't\", 'nor', 'not', 'being', 'are', 'your', 'over', 'off', 'having', 'by', \"won't\", 'myself', 'out', 'more', \"wasn't\", \"doesn't\", 'won', 'this', 'my', 'again', 'ma', 'his', 'when', 'you', 'there', 'herself', 'yourselves', 'itself', 'of', \"she's\", 'needn', 'we', \"mustn't\", 'above', \"you're\", 'so', 'it', \"should've\", 'am', 'he', 'those', 'further', 'she', 'down', 'on', \"you'll\", 'for', 'other', 'any', 'their', 'from', 'each', 'most', 'because', 'and', 'few', 'in', \"you've\", 'o'}\n",
        "  text = tf.strings.lower(text)\n",
        "  text = tf.strings.strip(text)\n",
        "  text = tf.strings.regex_replace(text, \"<[^>]+>\", \"\")\n",
        "  text = tf.strings.regex_replace(text, '[%s]' % marksp, \"\")\n",
        "  for soword in sowords:\n",
        "    text = tf.strings.regex_replace(text, r\"\\b%s\\b\" % soword, \"\")\n",
        "  return text\n",
        "example1 = \"Is COVID really happening and is it deadly?\"\n",
        "print(check_letters(example1))"
      ],
      "metadata": {
        "id": "gahK9NRuZYVP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b5a101b-1ee7-445b-cf82-7e8c158c18e4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b' covid really happening    deadly', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def token_define(train_ds, worcount, lenmmax, output_mode = \"int\", standardize = \"lower_and_strip_marksp\"):\n",
        "  train_text = train_ds.map(lambda x, y : x)\n",
        "  ltokenl = tfl.TextVectorization(\n",
        "      standardize=standardize,\n",
        "      max_tokens=worcount,\n",
        "      output_sequence_length=lenmmax,\n",
        "      output_mode=output_mode\n",
        "  )\n",
        "  ltokenl.adapt(train_text)\n",
        "  return ltokenl"
      ],
      "metadata": {
        "id": "2qGMLwHIZdQX"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def token_definition(train_ds, worcount, lenmmax=None, output_mode = \"int\", standardize = \"lower_and_strip_marksp\"):\n",
        "  train_text = train_ds.map(lambda x, y : x)\n",
        "  ltokenl = tfl.TextVectorization(\n",
        "      standardize=standardize,\n",
        "      max_tokens=worcount,\n",
        "      output_mode=output_mode\n",
        "  )\n",
        "  ltokenl.adapt(train_text)\n",
        "  return ltokenl"
      ],
      "metadata": {
        "id": "bAqbNotTauzd"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ltokenl = token_definition(train_ds, worcount, lenmmax, standardize=check_letters)"
      ],
      "metadata": {
        "id": "plFWVQLpa0vD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_pretrained_initial(url, output_file, embedding_file, embedding_dim, vocabulary, worcount, lenmmax):\n",
        "  embedding_vecs = dict()\n",
        "  word_idx = dict(zip(vocabulary, range(len(vocabulary))))\n",
        "  file_dir = get_file(output_file, url)\n",
        "  with zipfile.ZipFile(file_dir, \"r\") as f:\n",
        "    f.extractall(\"/content/\")\n",
        "  with open(embedding_file, \"r\") as f:\n",
        "    for line in f:\n",
        "      values = line.split()\n",
        "      word = values[0]\n",
        "      embedding_vec = np.asarray(values[1:], dtype='float32')\n",
        "      embedding_vecs[word] = embedding_vec\n",
        "  embedding_matrix = np.zeros((worcount, embedding_dim))\n",
        "  for word, idx in word_idx.items():\n",
        "    if idx < worcount:\n",
        "      embedding_vec = embedding_vecs.get(word)\n",
        "      if embedding_vec is not None:\n",
        "        embedding_matrix[idx] = embedding_vec\n",
        "  \n",
        "  embedding = tfl.Embedding(worcount, embedding_dim, embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix), mask_zero=True, input_length=lenmmax, trainable=False)\n",
        "  return embedding"
      ],
      "metadata": {
        "id": "iV7XMeBegXkq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_pretrained_after(url, output_file, embedding_file, embedding_dim, vocabulary, worcount, lenmmax=None):\n",
        "  embedding_vecs = dict()\n",
        "  word_idx = dict(zip(vocabulary, range(len(vocabulary))))\n",
        "  file_dir = get_file(output_file, url)\n",
        "\n",
        "  with zipfile.ZipFile(file_dir, \"r\") as f:\n",
        "    f.extractall(\"/content/\")\n",
        "\n",
        "  with open(embedding_file, \"r\") as f:\n",
        "    for line in f:\n",
        "      values = line.split()\n",
        "      word = values[0]\n",
        "      embedding_vec = np.asarray(values[1:], dtype='float32')\n",
        "      embedding_vecs[word] = embedding_vec\n",
        "\n",
        "  embedding_matrix = np.zeros((worcount, embedding_dim))\n",
        "  \n",
        "  for word, idx in word_idx.items():\n",
        "    if idx < worcount:\n",
        "      embedding_vec = embedding_vecs.get(word)\n",
        "      if embedding_vec is not None:\n",
        "        embedding_matrix[idx] = embedding_vec\n",
        "  \n",
        "  embedding = tfl.Embedding(worcount, embedding_dim, embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix), input_dim=len(vocabulary), trainable=False)\n",
        "  return embedding"
      ],
      "metadata": {
        "id": "hEvynXMNgfPJ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = ltokenl.get_vocabulary()\n",
        "embedding = check_pretrained_initial(\"https://nlp.stanford.edu/data/glove.6B.zip\", \"glove.6B.zip\", \"glove.6B.100d.txt\", 100, vocabulary=vocabulary, worcount=worcount, lenmmax=lenmmax)\n"
      ],
      "metadata": {
        "id": "LThLcntaghfx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7cb0202-121b-4d4f-a071-ff55f99a1aed"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://nlp.stanford.edu/data/glove.6B.zip\n",
            "862182613/862182613 [==============================] - 159s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def review_fake_check(ltokenl, embedding_layer, worcount, lenmmax, optimizer='adam'):\n",
        "  model = Sequential(\n",
        "      [\n",
        "      ltokenl,\n",
        "      embedding_layer,\n",
        "      tfl.Bidirectional(tfl.LSTM(128, return_sequences=True, input_shape=(worcount, lenmmax))),\n",
        "      tfl.Bidirectional(tfl.LSTM(128, return_sequences=False)),\n",
        "      #tfl.Bidirectional(tfl.LSTM(128)),\n",
        "      tfl.Dropout(0.2),\n",
        "      #tfl.Dense(128, activation='relu')\n",
        "      #tfl.Dense(64, activation='relu')\n",
        "      tfl.Dense(1, activation='sigmoid')\n",
        "      ]\n",
        "  )\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics = ['acc'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "metadata": {
        "id": "_KEsT_NNgnhc"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = review_fake_check(ltokenl, embedding, worcount, lenmmax)\n"
      ],
      "metadata": {
        "id": "LjZajTangp4r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8938b0de-65b7-45ad-d352-e27316d50958"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization (TextVec  (None, None)             0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 100)         10000000  \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, None, 256)        234496    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 256)              394240    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,628,993\n",
            "Trainable params: 628,993\n",
            "Non-trainable params: 10,000,000\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, TerminateOnNaN, EarlyStopping\n",
        "checkpoint_path = \"/content/\"\n",
        "callbacks = [\n",
        "             TensorBoard(),\n",
        "             ModelCheckpoint(checkpoint_path),\n",
        "             ReduceLROnPlateau(),\n",
        "             TerminateOnNaN(),\n",
        "             EarlyStopping(patience=2)\n",
        "]"
      ],
      "metadata": {
        "id": "ros6Geq0kd4P"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, training_ds, validation_ds = None, val_split = 0.2, batch_size = BATCH_SIZE, epochs=5, callbacks=callbacks):\n",
        "  if validation_ds is None:\n",
        "    trainable_check = model.fit(training_ds, validation_split=val_split, batch_size=batch_size, epochs=epochs, callbacks=callbacks)\n",
        "  else:\n",
        "    trainable_check = model.fit(training_ds, validation_data=validation_ds, batch_size=batch_size, epochs=epochs, callbacks=callbacks)\n",
        "  return trainable_check"
      ],
      "metadata": {
        "id": "rbWgzZKukvFS"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainable_check = train_model(model, train_ds, val_ds, epochs=3)\n"
      ],
      "metadata": {
        "id": "kQhIjxP6kx9z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b842d941-feda-4f80-b91e-5c02246ddbfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "  68801/Unknown - 14424s 209ms/step - loss: 0.0416 - acc: 0.9836"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68801/68801 [==============================] - 15125s 220ms/step - loss: 0.0416 - acc: 0.9836 - val_loss: 0.0086 - val_acc: 0.9964 - lr: 0.0010\n",
            "Epoch 2/3\n",
            "15963/68801 [=====>........................] - ETA: 3:03:54 - loss: 0.0093 - acc: 0.9963"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflowjs as tfjs\n",
        "def model_to_tfhs(model, output_dir):\n",
        "  tfjs.converters.save_keras_model(model, output_dir)"
      ],
      "metadata": {
        "id": "7xiFIQmymRm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_result = model().predict(embedding)\n",
        "\n",
        "prediction = []\n",
        "for i in range (len(predicted_result)):\n",
        "  if predicted_result[i].item() > 0.5:\n",
        "    prediction.append(1)\n",
        "  else:\n",
        "    prediction.append(0)\n",
        "    \n",
        "\n",
        "#accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(list(test_ds), prediction)\n",
        "\n",
        "print(accuracy)"
      ],
      "metadata": {
        "id": "TQ_VCJKAR3Qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/model2\")"
      ],
      "metadata": {
        "id": "GvLOEqOumSVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del model"
      ],
      "metadata": {
        "id": "OhnfaZZfmZcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "clone = load_model('/content/model1')"
      ],
      "metadata": {
        "id": "MBUUnAiRmajR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv saved_model '/content/backup'"
      ],
      "metadata": {
        "id": "_YEfbqeqmkpi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}